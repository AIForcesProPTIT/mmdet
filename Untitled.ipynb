{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "operating-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config, DictAction\n",
    "config_file = './configs/resnest/cascade_rcnn_s50_fpn_syncbn-backbone+head_mstrain-range_1x_coco.py'\n",
    "# config_file = './configs/rpn/rpn_r50_fpn_1x_coco.py'\n",
    "cfg = Config.fromfile(config_file)\n",
    "cfg.data.imgs_per_gpu=8\n",
    "cfg.data.samples_per_gpu = cfg.data.imgs_per_gpu\n",
    "cfg['seed'] = 12\n",
    "cfg['exp_name'] = 'tuenguyen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "least-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "albu_train_transforms = [\n",
    "    dict(\n",
    "        type='HorizontalFlip',\n",
    "        p=0.5),\n",
    "    dict(\n",
    "        type='VerticalFlip',\n",
    "        p=0.5),\n",
    "\n",
    "    dict(\n",
    "        type='ShiftScaleRotate',\n",
    "        shift_limit=0.0625,\n",
    "        scale_limit=0.0,\n",
    "        rotate_limit=180,\n",
    "        interpolation=1,\n",
    "        p=0.5),\n",
    "        # p='abcde'),#故意写错，看看是否真的考虑了这段代码 #我去，真的定位到了albu库\n",
    "    dict(\n",
    "        type='RandomBrightnessContrast',\n",
    "        brightness_limit=[0.1, 0.3],\n",
    "        contrast_limit=[0.1, 0.3],\n",
    "        p=0.2),\n",
    "    # dict(\n",
    "    #     type='OneOf',\n",
    "    #     transforms=[\n",
    "    #         dict(\n",
    "    #             type='RGBShift',\n",
    "    #             r_shift_limit=10,\n",
    "    #             g_shift_limit=10,\n",
    "    #             b_shift_limit=10,\n",
    "    #             p=1.0),\n",
    "    #         dict(\n",
    "    #             type='HueSaturationValue',\n",
    "    #             hue_shift_limit=20,\n",
    "    #             sat_shift_limit=30,\n",
    "    #             val_shift_limit=20,\n",
    "    #             p=1.0)\n",
    "    #     ],\n",
    "    #     p=0.1),\n",
    "    # # dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
    "    #\n",
    "    # dict(type='ChannelShuffle', p=0.1),\n",
    "    # dict(\n",
    "    #     type='OneOf',\n",
    "    #     transforms=[\n",
    "    #         dict(type='Blur', blur_limit=3, p=1.0),\n",
    "    #         dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
    "    #     ],\n",
    "    #     p=0.1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ancient-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict(\n",
    "    type='CascadeRCNN',\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        frozen_stages=1,\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        norm_eval=True,\n",
    "        style='pytorch'),\n",
    "    neck=dict(\n",
    "        type='FPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    rpn_head=dict(\n",
    "        type='RPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[.0, .0, .0, .0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
    "    roi_head=dict(\n",
    "        type='CascadeRoIHead',\n",
    "        num_stages=3,\n",
    "        stage_loss_weights=[1, 0.5, 0.25],\n",
    "        bbox_roi_extractor=dict(\n",
    "            type='SingleRoIExtractor',\n",
    "            roi_layer=dict(type='RoIAlign', out_size=7, sample_num=0),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        bbox_head=[\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=14,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=14,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=14,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
    "        ]))\n",
    "# model training and testing settings\n",
    "train_cfg = dict(\n",
    "    rpn=dict(\n",
    "        assigner=dict(\n",
    "            type='MaxIoUAssigner',\n",
    "            pos_iou_thr=0.7,\n",
    "            neg_iou_thr=0.3,\n",
    "            min_pos_iou=0.3,\n",
    "            match_low_quality=True,\n",
    "            ignore_iof_thr=-1),\n",
    "        sampler=dict(\n",
    "            type='RandomSampler',\n",
    "            num=256,\n",
    "            pos_fraction=0.5,\n",
    "            neg_pos_ub=-1,\n",
    "            add_gt_as_proposals=False),\n",
    "        allowed_border=0,\n",
    "        pos_weight=-1,\n",
    "        debug=False),\n",
    "    rpn_proposal=dict(\n",
    "        nms_across_levels=False,\n",
    "        nms_pre=2000,\n",
    "        nms_post=2000,\n",
    "        max_num=2000,\n",
    "        nms_thr=0.7,\n",
    "        min_bbox_size=0),\n",
    "    rcnn=[\n",
    "        dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.5,\n",
    "                neg_iou_thr=0.5,\n",
    "                min_pos_iou=0.5,\n",
    "                match_low_quality=False,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=512,\n",
    "                pos_fraction=0.25,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=True),\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.6,\n",
    "                neg_iou_thr=0.6,\n",
    "                min_pos_iou=0.6,\n",
    "                match_low_quality=False,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=512,\n",
    "                pos_fraction=0.25,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=True),\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.7,\n",
    "                min_pos_iou=0.7,\n",
    "                match_low_quality=False,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=512,\n",
    "                pos_fraction=0.25,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=True),\n",
    "            pos_weight=-1,\n",
    "            debug=False)\n",
    "    ])\n",
    "test_cfg = dict(\n",
    "    rpn=dict(\n",
    "        nms_across_levels=False,\n",
    "        nms_pre=1000,\n",
    "        nms_post=1000,\n",
    "        max_num=1000,\n",
    "        nms_thr=0.7,\n",
    "        min_bbox_size=0),\n",
    "    rcnn=dict(\n",
    "        score_thr=0.05, nms=dict(type='nms', iou_thr=0.5), max_per_img=100))\n",
    "\n",
    "\n",
    "\n",
    "###################################coco_detection.py#############################\n",
    "dataset_type = 'CocoDataset'\n",
    "data_root = '/home/tuenguyen/Desktop/mmdet/mmdetection/vin_data_dowscale_3x_with_coco/' #记得加/\n",
    "\n",
    "\n",
    "\n",
    "#这个后续再改吧\n",
    "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    \n",
    "    # 如果是新手那就按照默认参数的比例扩大就行了，然后测试的时候取训练集的中间值。比如cascade50默认尺度是(1333,800)\n",
    "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),# The largest scale of image\n",
    "    # dict(type='Resize',img_scale=[(2000, 300), (2000, 1200)],multiscale_mode='range',keep_ratio=True), #别的代码看到了这种结构\n",
    "    \n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "\n",
    "    # 知乎贴子增加的，和前面的段落配合\n",
    "    dict(\n",
    "    type='Albu',\n",
    "    transforms=albu_train_transforms,\n",
    "    bbox_params=dict(\n",
    "        type='BboxParams',\n",
    "        format='pascal_voc',\n",
    "        label_fields=['gt_labels'],\n",
    "        min_visibility=0.0,\n",
    "        filter_lost_elements=True),\n",
    "    keymap={\n",
    "        'img': 'image',\n",
    "        'gt_bboxes': 'bboxes'\n",
    "    },\n",
    "    update_pad_shape=False,\n",
    "    skip_img_without_anno=True),\n",
    "    \n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        \n",
    "        #test_pipeline 中img_scale的尺度可以为任意多个，含义为对测试集进行多尺度测试（可以理解为TTA）\n",
    "        img_scale=(1333, 800),\n",
    "        \n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        #ann_file=data_root + 'annotations/instances_train2017.json',\n",
    "        #img_prefix=data_root + 'train2017/',\n",
    "        ann_file=data_root + '/train_annotations.json',\n",
    "        img_prefix=data_root,\n",
    "        pipeline=train_pipeline),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        #ann_file=data_root + 'annotations/instances_val2017.json',\n",
    "        #img_prefix=data_root + 'val2017/',\n",
    "        ann_file=data_root + '/val_annotations.json',\n",
    "        img_prefix=data_root ,\n",
    "        pipeline=test_pipeline),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        #ann_file=data_root + 'annotations/instances_val2017.json',\n",
    "        #img_prefix=data_root + 'val2017/',\n",
    "        pipeline=test_pipeline)\n",
    ")\n",
    "evaluation = dict(interval=5, metric='bbox')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################schedule_1x.py#################################\n",
    "# optimizer\n",
    "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
    "optimizer_config = dict(grad_clip=None)\n",
    "# learning policy\n",
    "lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=500,\n",
    "    warmup_ratio=0.001,\n",
    "    step=[8, 11])\n",
    "total_epochs = 50 #epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################default_runtime.py#############################\n",
    "checkpoint_config = dict(interval=10)\n",
    "# yapf:disable\n",
    "log_config = dict(\n",
    "    interval=50,\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        # dict(type='TensorboardLoggerHook')\n",
    "    ])\n",
    "# yapf:enable\n",
    "dist_params = dict(backend='nccl')\n",
    "log_level = 'INFO'\n",
    "load_from = None\n",
    "resume_from = None\n",
    "workflow = [('train', 1)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################生成配置###############################\n",
    "config_dict=dict(\n",
    "    model = model,\n",
    "    train_cfg = train_cfg,\n",
    "    test_cfg  = test_cfg ,\n",
    "    dataset_type =dataset_type,\n",
    "    data_root=data_root,\n",
    "    img_norm_cfg=img_norm_cfg,\n",
    "    train_pipeline=train_pipeline,\n",
    "    test_pipeline=test_pipeline,\n",
    "    data =data ,\n",
    "    evaluation =evaluation ,\n",
    "    optimizer=optimizer,\n",
    "    optimizer_config=optimizer_config,\n",
    "    lr_config=lr_config,\n",
    "    total_epochs=total_epochs,\n",
    "    checkpoint_config=checkpoint_config,\n",
    "    log_config=log_config,\n",
    "    dist_params=dist_params,\n",
    "    log_level=log_level,\n",
    "    load_from =load_from ,\n",
    "    resume_from=resume_from,\n",
    "    workflow =workflow \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "cfg_real_time = Config(config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dominican-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import collect_env, get_root_logger\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train a detector')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--no-validate',\n",
    "        action='store_true',\n",
    "        help='whether not to evaluate the checkpoint during training')\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file (deprecate), '\n",
    "        'change to --cfg-options instead.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. If the value to '\n",
    "        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "        'Note that the quotation marks are necessary and that no white space '\n",
    "        'is allowed.')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    if args.options and args.cfg_options:\n",
    "        raise ValueError(\n",
    "            '--options and --cfg-options cannot be both '\n",
    "            'specified, --options is deprecated in favor of --cfg-options')\n",
    "    if args.options:\n",
    "        warnings.warn('--options is deprecated in favor of --cfg-options')\n",
    "        args.cfg_options = args.options\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    if args.cfg_options is not None:\n",
    "        cfg.merge_from_dict(args.cfg_options)\n",
    "    # import modules from string list.\n",
    "    if cfg.get('custom_imports', None):\n",
    "        from mmcv.utils import import_modules_from_strings\n",
    "        import_modules_from_strings(**cfg['custom_imports'])\n",
    "    # set cudnn_benchmark\n",
    "    if cfg.get('cudnn_benchmark', False):\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # work_dir is determined in this priority: CLI > segment in file > filename\n",
    "    if args.work_dir is not None:\n",
    "        # update configs according to CLI args if args.work_dir is not None\n",
    "        cfg.work_dir = args.work_dir\n",
    "    elif cfg.get('work_dir', None) is None:\n",
    "        # use config filename as default work_dir if cfg.work_dir is None\n",
    "        cfg.work_dir = osp.join('./work_dirs',\n",
    "                                osp.splitext(osp.basename(args.config))[0])\n",
    "    if args.resume_from is not None:\n",
    "        cfg.resume_from = args.resume_from\n",
    "    if args.gpu_ids is not None:\n",
    "        cfg.gpu_ids = args.gpu_ids\n",
    "    else:\n",
    "        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    if args.launcher == 'none':\n",
    "        distributed = False\n",
    "    else:\n",
    "        distributed = True\n",
    "        init_dist(args.launcher, **cfg.dist_params)\n",
    "        # re-set gpu_ids with distributed training mode\n",
    "        _, world_size = get_dist_info()\n",
    "        cfg.gpu_ids = range(world_size)\n",
    "\n",
    "    # create work_dir\n",
    "    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "    # dump config\n",
    "    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "    # init the logger before other steps\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "    log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "    logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "    # init the meta dict to record some important information such as\n",
    "    # environment info and seed, which will be logged\n",
    "    meta = dict()\n",
    "    # log env info\n",
    "    env_info_dict = collect_env()\n",
    "    env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "    dash_line = '-' * 60 + '\\n'\n",
    "    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "                dash_line)\n",
    "    meta['env_info'] = env_info\n",
    "    meta['config'] = cfg.pretty_text\n",
    "    # log some basic info\n",
    "    logger.info(f'Distributed training: {distributed}')\n",
    "    logger.info(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "    # set random seeds\n",
    "    if args.seed is not None:\n",
    "        logger.info(f'Set random seed to {args.seed}, '\n",
    "                    f'deterministic: {args.deterministic}')\n",
    "        set_random_seed(args.seed, deterministic=args.deterministic)\n",
    "    cfg.seed = args.seed\n",
    "    meta['seed'] = args.seed\n",
    "    meta['exp_name'] = osp.basename(args.config)\n",
    "\n",
    "    model = build_detector(\n",
    "        cfg.model,\n",
    "        train_cfg=cfg.get('train_cfg'),\n",
    "        test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "    datasets = [build_dataset(cfg.data.train)]\n",
    "    if len(cfg.workflow) == 2:\n",
    "        val_dataset = copy.deepcopy(cfg.data.val)\n",
    "        val_dataset.pipeline = cfg.data.train.pipeline\n",
    "        datasets.append(build_dataset(val_dataset))\n",
    "    if cfg.checkpoint_config is not None:\n",
    "        # save mmdet version, config file content and class names in\n",
    "        # checkpoints as meta data\n",
    "        cfg.checkpoint_config.meta = dict(\n",
    "            mmdet_version=__version__ + get_git_hash()[:7],\n",
    "            CLASSES=datasets[0].CLASSES)\n",
    "    # add an attribute for visualization convenience\n",
    "    model.CLASSES = datasets[0].CLASSES\n",
    "    train_detector(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=distributed,\n",
    "        validate=(not args.no_validate),\n",
    "        timestamp=timestamp,\n",
    "        meta=meta)\n",
    "\n",
    "\n",
    "\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confidential-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets.coco import CocoDataset\n",
    "# datasetx.proposal_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lucky-grave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "here\n",
      "3296\n",
      "3296\n",
      "here ne\n",
      "2694\n",
      "here ne\n",
      "2694\n"
     ]
    }
   ],
   "source": [
    "# d\n",
    "data = build_dataset(cfg_real_time.data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "explicit-accounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_metas': DataContainer({'filename': '/home/tuenguyen/Desktop/mmdet/mmdetection/vin_data_dowscale_3x_with_coco/train_images/bf33d826094fabd938f69b3ba663f607.jpg', 'ori_filename': 'train_images/bf33d826094fabd938f69b3ba663f607.jpg', 'ori_shape': (1004, 1023, 3), 'img_shape': (800, 815, 3), 'pad_shape': (800, 832, 3), 'scale_factor': array([0.79667646, 0.7968128 , 0.79667646, 0.7968128 ], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}),\n",
       " 'img': DataContainer(tensor([[[-0.4886, -0.4839, -0.4840,  ..., -1.7073, -1.6946, -1.7187],\n",
       "          [-0.4235, -0.4557, -0.4532,  ..., -1.7275, -1.7105, -1.7234],\n",
       "          [-0.4151, -0.4611, -0.4697,  ..., -1.7085, -1.7071, -1.7122],\n",
       "          ...,\n",
       "          [-1.7572, -1.7583, -1.7620,  ..., -1.8782, -1.8782, -1.8782],\n",
       "          [-1.7412, -1.7438, -1.7563,  ..., -1.8766, -1.8782, -1.8782],\n",
       "          [-1.7412, -1.7413, -1.7476,  ..., -1.8702, -1.8782, -1.8782]],\n",
       " \n",
       "         [[-0.3701, -0.3652, -0.3653,  ..., -1.6159, -1.6030, -1.6276],\n",
       "          [-0.3035, -0.3364, -0.3338,  ..., -1.6366, -1.6192, -1.6325],\n",
       "          [-0.2949, -0.3419, -0.3508,  ..., -1.6172, -1.6157, -1.6210],\n",
       "          ...,\n",
       "          [-1.6670, -1.6681, -1.6718,  ..., -1.7906, -1.7906, -1.7906],\n",
       "          [-1.6506, -1.6533, -1.6660,  ..., -1.7890, -1.7906, -1.7906],\n",
       "          [-1.6506, -1.6507, -1.6571,  ..., -1.7825, -1.7906, -1.7906]],\n",
       " \n",
       "         [[-0.1462, -0.1414, -0.1415,  ..., -1.3865, -1.3736, -1.3981],\n",
       "          [-0.0799, -0.1127, -0.1101,  ..., -1.4071, -1.3898, -1.4030],\n",
       "          [-0.0713, -0.1182, -0.1270,  ..., -1.3877, -1.3863, -1.3916],\n",
       "          ...,\n",
       "          [-1.4373, -1.4384, -1.4422,  ..., -1.5604, -1.5604, -1.5604],\n",
       "          [-1.4210, -1.4237, -1.4364,  ..., -1.5589, -1.5604, -1.5604],\n",
       "          [-1.4210, -1.4211, -1.4275,  ..., -1.5523, -1.5604, -1.5604]]])),\n",
       " 'gt_bboxes': DataContainer(tensor([[368.6964, 177.4652, 679.1903, 361.0292]])),\n",
       " 'gt_labels': DataContainer(tensor([2]))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(data.ann_file,\"r\") as f:\n",
    "    u = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detector(\n",
    "        cfg.model,\n",
    "        train_cfg=cfg.get('train_cfg'),\n",
    "        test_cfg=cfg.get('test_cfg'))\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = datasets[0].coco.load_imgs([1])[0]\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_detector(config_file,  device='cuda')\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "data_loaders = [\n",
    "        build_dataloader(\n",
    "            ds,\n",
    "            cfg.data.samples_per_gpu,\n",
    "            cfg.data.workers_per_gpu,\n",
    "            # cfg.gpus will be ignored if distributed\n",
    "            1,\n",
    "            dist=False,\n",
    "            seed=cfg.seed) for ds in datasets\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(data_loaders[0]))\n",
    "datasets[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([i.numel() for i in model.parameters()]))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "img =torch.randn(2,3,512,512).float().to(\"cuda\")\n",
    "bboxes = torch.from_numpy(np.array([0.,0.,120.,240.,120.,120.,220,220]).reshape(-1,4) ).float().to(\"cuda\")\n",
    "labels = torch.from_numpy(np.array([1,2])).to(\"cuda\")\n",
    "colected = [{\n",
    "    'ori_shape':(512,512,3),\n",
    "    'pad_shape':(512,512,3),\n",
    "    'img_shape':(512,512,3),\n",
    "    'scale_factor':(1.,1.,1.,1.)\n",
    "    \n",
    "},{\n",
    "\n",
    "    'ori_shape':(512,512,3),\n",
    "    'pad_shape':(512,512,3),\n",
    "    'img_shape':(512,512,3),\n",
    "    'scale_factor':(1.,1.,1.,1.)\n",
    "    \n",
    "}]\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img,colected, gt_bboxes = [bboxes,]*2,gt_labels = [labels,]*2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_cfg.get('rpn_proposal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "3*(8**2 + 16 ** 2 + 32 ** 2 + 64 **2 + 128 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roi_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "5440 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "512//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "21824 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-chase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
